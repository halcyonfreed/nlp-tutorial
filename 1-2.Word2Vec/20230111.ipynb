{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm_gui\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.utils.data import TensorDataset,DataLoader\n",
    "device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "dtype=torch.FloatTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [\"jack like dog\", \"jack like cat\", \"jack like animal\",\n",
    "  \"dog cat animal\", \"banana apple cat dog like\", \"dog fish milk like\",\n",
    "  \"dog cat animal like\", \"jack like apple\", \"apple like\", \"jack like banana\",\n",
    "  \"apple banana jack movie book music like\", \"cat dog hate\", \"cat dog like\"]\n",
    "sentences_list=\" \".join(sentences).split()\n",
    "vocab=list(set(sentences_list))\n",
    "word2idx={w:i for i,w in enumerate(vocab)}\n",
    "vocab_size=len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model parameters\n",
    "C=2\n",
    "batch_size=8\n",
    "m=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "skip_grams=[]\n",
    "for idx in range(C,len(sentences_list)-C):\n",
    "    center=word2idx[sentences_list[idx]]\n",
    "    context_idx=list(range(idx-C,idx))+list(range(idx+1,idx+C+1))\n",
    "    context=[word2idx[sentences_list[i]] for i in context_idx]\n",
    "\n",
    "    for w in context:\n",
    "        skip_grams.append([center,w])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_data(skip_grams):\n",
    "    x,y=[],[]\n",
    "    for a,b in skip_grams:\n",
    "        x.append(np.eye(vocab_size)[a])\n",
    "        y.append(b)\n",
    "    return x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y=make_data(skip_grams)\n",
    "x,y=torch.Tensor(x),torch.Tensor(y)\n",
    "dataset=TensorDataset(x,y)\n",
    "loader=DataLoader(dataset,batch_size,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Word2Vec(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Word2Vec,self).__init__()\n",
    "        self.W=nn.Parameter(torch.randn(vocab_size,m).type(dtype))\n",
    "        self.V=nn.Parameter(torch.randn(m,vocab_size).type(dtype))\n",
    "    def forward(self,x):\n",
    "        hidden=torch.mm(x,self.W)\n",
    "        output=torch.mm(hidden,self.V)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Word2Vec().to(device)\n",
    "loss_fn=nn.CrossEntropyLoss().to(device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.11 ('week6')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "dc22443302a7e1520fd496d19808d411f95cd97f052bed8809baa60e4c089c3b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
