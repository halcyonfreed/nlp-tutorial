{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from tqdm.auto import tqdm\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.utils.data import TensorDataset,DataLoader\n",
    "device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "dtype=torch.FloatTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [\"jack like dog\", \"jack like cat\", \"jack like animal\",\n",
    "  \"dog cat animal\", \"banana apple cat dog like\", \"dog fish milk like\",\n",
    "  \"dog cat animal like\", \"jack like apple\", \"apple like\", \"jack like banana\",\n",
    "  \"apple banana jack movie book music like\", \"cat dog hate\", \"cat dog like\"]\n",
    "sentences_list=\" \".join(sentences).split()\n",
    "vocab=list(set(sentences_list))\n",
    "word2idx={w:i for i,w in enumerate(vocab)}\n",
    "vocab_size=len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model parameters\n",
    "C=2\n",
    "batch_size=8\n",
    "m=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "skip_grams=[]\n",
    "for idx in range(C,len(sentences_list)-C):\n",
    "    center=word2idx[sentences_list[idx]]\n",
    "    context_idx=list(range(idx-C,idx))+list(range(idx+1,idx+C+1))\n",
    "    context=[word2idx[sentences_list[i]] for i in context_idx]\n",
    "\n",
    "    for w in context:\n",
    "        skip_grams.append([center,w])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_data(skip_grams):\n",
    "    x,y=[],[]\n",
    "    for a,b in skip_grams:\n",
    "        x.append(np.eye(vocab_size)[a])\n",
    "        y.append(b)\n",
    "    return x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mephistopheles\\AppData\\Local\\Temp\\ipykernel_15232\\2563640646.py:2: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\torch\\csrc\\utils\\tensor_new.cpp:204.)\n",
      "  x,y=torch.Tensor(x),torch.LongTensor(y)\n"
     ]
    }
   ],
   "source": [
    "x,y=make_data(skip_grams)\n",
    "x,y=torch.Tensor(x),torch.LongTensor(y)\n",
    "dataset=TensorDataset(x,y)\n",
    "loader=DataLoader(dataset,batch_size,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Word2Vec(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Word2Vec,self).__init__()\n",
    "        self.W=nn.Parameter(torch.randn(vocab_size,m).type(dtype))\n",
    "        self.V=nn.Parameter(torch.randn(m,vocab_size).type(dtype))\n",
    "    def forward(self,x):\n",
    "        hidden=torch.mm(x,self.W)\n",
    "        output=torch.mm(hidden,self.V)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Word2Vec().to(device)\n",
    "criterion=nn.CrossEntropyLoss()\n",
    "optim=torch.optim.Adam(model.parameters(),lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fab9768e69224f3ea0170bed717135a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/21 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11902589026741bfae40c006d9da58d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/21 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9bb12c5ca44d42f186d41489dc57883a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/21 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9f5598c3f994af483415f23a9a93816",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/21 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "599218477e674f069ccc104c606a3ef2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/21 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f923fb3499c474aa793afd58a01a32f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/21 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed5750a988d940ca9f12dbf1a2228b11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/21 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "413577e9bd444be3abbbc66bd2a884c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/21 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "547862e875f84ea2b8066f83c7a04615",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/21 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39178fcdeae04645b92c7ab5a8fe85cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/21 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "writer=SummaryWriter()\n",
    "step=0\n",
    "for epoch in range(10):\n",
    "    loss_record=[]\n",
    "    for batch_x,batch_y in tqdm(loader):\n",
    "        batch_x,batch_y=batch_x.to(device),batch_y.to(device)\n",
    "        pred=model(batch_x)\n",
    "        loss=criterion(pred,batch_y)\n",
    "        loss_record.append(loss)\n",
    "        optim.zero_grad()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "\n",
    "        step+=1\n",
    "    mean_train_loss=sum(loss_record)/len(loss_record)\n",
    "    writer.add_scalar(\"trainloss\",mean_train_loss,step)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 3.0464e-01,  1.6175e+00],\n",
      "        [-2.0618e-01,  1.6635e+00],\n",
      "        [-4.9500e-01,  2.8918e-01],\n",
      "        [-2.0196e-01,  9.1923e-01],\n",
      "        [-1.4689e+00,  2.0688e+00],\n",
      "        [-3.0941e-01, -5.6723e-01],\n",
      "        [ 1.9653e-01,  7.6729e-01],\n",
      "        [-6.7791e-01,  1.0789e+00],\n",
      "        [ 2.5823e-01,  7.6374e-01],\n",
      "        [-6.5075e-01, -6.0112e-01],\n",
      "        [-1.7608e+00,  7.8554e-04],\n",
      "        [-1.3077e+00,  5.0368e-01],\n",
      "        [-1.7800e+00,  7.3736e-02]], requires_grad=True) Parameter containing:\n",
      "tensor([[-0.5806,  0.4541, -0.5058, -1.7984, -0.1472, -0.1695, -0.2166, -0.9295,\n",
      "          1.7202, -1.9656, -0.4188, -0.1822, -0.8080],\n",
      "        [ 0.1001,  0.5571, -1.0630,  0.2788,  1.5641, -0.2742, -0.3473, -1.2679,\n",
      "          0.7953,  1.0516,  0.0766, -0.3992, -0.3814]], requires_grad=True)\n",
      "0.30464044213294983 1.617525339126587\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "for i,label in enumerate(vocab):\n",
    "    w,wt=model.parameters()\n",
    "    print(w,wt)\n",
    "    x,y=float(w[i][0]),float(w[i][1])\n",
    "    print(x,y)\n",
    "    plt.scatter(x,y)\n",
    "    plt.annotate(label,xy=(x,y),xytext=(5,2))#,textcoords=)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.11 ('week6')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "dc22443302a7e1520fd496d19808d411f95cd97f052bed8809baa60e4c089c3b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
