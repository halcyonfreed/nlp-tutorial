{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "sjNbhLpVNceY"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "  code by Tae Hwan Jung(Jeff Jung) @graykode, modify by wmathor\n",
        "'''\n",
        "import torch\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.utils.data as Data\n",
        "import torch.nn.functional as F\n",
        "\n",
        "dtype = torch.FloatTensor\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "preprocess data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "5jaRDe00eqZZ"
      },
      "outputs": [],
      "source": [
        "# 3 words sentences (=sequence_length is 3)\n",
        "sentences = [\"i love you\", \"he loves me\", \"she likes baseball\", \"i hate you\", \"sorry for that\", \"this is awful\"]\n",
        "labels = [1, 1, 1, 0, 0, 0]  # 1 is good, 0 is not good.\n",
        "\n",
        "# TextCNN Parameter\n",
        "embedding_size = 2 # wordemb dim 就是前面的词向量表的m=2\n",
        "sequence_length = len(sentences[0]) # every sentences contains sequence_length(=3) words\n",
        "num_classes = len(set(labels))  # 0 or 1\n",
        "batch_size = 3 #3句话一起看\n",
        "\n",
        "word_list = \" \".join(sentences).split() #sentences这个序列的每个成员后面加\" \",最后split成为一个list，成员是str\n",
        "vocab = list(set(word_list))\n",
        "word2idx = {w: i for i, w in enumerate(vocab)}\n",
        "vocab_size = len(vocab) #就是前面的词向量表的V"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "O6kGPKVrNiJJ"
      },
      "outputs": [],
      "source": [
        "def make_data(sentences, labels):\n",
        "  inputs = []\n",
        "  for sen in sentences:\n",
        "      inputs.append([word2idx[n] for n in sen.split()])\n",
        "\n",
        "  targets = []\n",
        "  for out in labels: #就是输出好还是坏 0或1\n",
        "      targets.append(out) # To using Torch Softmax Loss function\n",
        "  return inputs, targets\n",
        "\n",
        "input_batch, target_batch = make_data(sentences, labels)\n",
        "input_batch, target_batch = torch.LongTensor(input_batch), torch.LongTensor(target_batch)\n",
        "\n",
        "dataset = Data.TensorDataset(input_batch, target_batch)\n",
        "loader = Data.DataLoader(dataset, batch_size, True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "dzhILRnNVS-a"
      },
      "outputs": [],
      "source": [
        "class TextCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(TextCNN, self).__init__()\n",
        "        self.W = nn.Embedding(vocab_size, embedding_size) #这个就是1-1里的词向量表C\n",
        "        output_channel = 3\n",
        "        self.conv = nn.Sequential(\n",
        "            # conv : [input_channel(=1), output_channel, (filter_height, filter_width), stride=1]\n",
        "            nn.Conv2d(1, output_channel, (2, embedding_size)), # => [batch_size, output_channel, 2, 1]\n",
        "            nn.ReLU(),\n",
        "            # pool : ((filter_height, filter_width))\n",
        "            nn.MaxPool2d((2, 1)),\n",
        "        )\n",
        "        # fc\n",
        "        self.fc = nn.Linear(output_channel, num_classes)\n",
        "\n",
        "    def forward(self, X):\n",
        "      '''\n",
        "      X: [batch_size, sequence_length]\n",
        "      '''\n",
        "    #   print(X.shape) #输出torch.Size([3, 3])\n",
        "      batch_size = X.shape[0]\n",
        "      embedding_X = self.W(X) # [batch_size, sequence_length, embedding_size]\n",
        "      embedding_X = embedding_X.unsqueeze(1) # 一共0,1,2三个维度看上面，加在1这个位置，add channel(=1) [batch, channel(=1), sequence_length, embedding_size]\n",
        "      \n",
        "      conved = self.conv(embedding_X) # [batch_size, output_channel, 1, 1]\n",
        "      flatten = conved.view(batch_size, -1) #列数batch_size,行数不定是-1为啥呢 [batch_size, output_channel*1*1]\n",
        "      output = self.fc(flatten)\n",
        "      return output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        },
        "colab_type": "code",
        "id": "_KQFe0ZZVsJS",
        "outputId": "dfce89a5-62b2-40e3-b7b9-4561064ae27b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([3, 3])\n",
            "torch.Size([3, 3])\n",
            "torch.Size([3, 3])\n",
            "torch.Size([3, 3])\n",
            "torch.Size([3, 3])\n",
            "torch.Size([3, 3])\n",
            "torch.Size([3, 3])\n",
            "torch.Size([3, 3])\n",
            "torch.Size([3, 3])\n",
            "torch.Size([3, 3])\n",
            "torch.Size([3, 3])\n",
            "torch.Size([3, 3])\n",
            "torch.Size([3, 3])\n",
            "torch.Size([3, 3])\n",
            "torch.Size([3, 3])\n",
            "torch.Size([3, 3])\n",
            "torch.Size([3, 3])\n",
            "torch.Size([3, 3])\n",
            "torch.Size([3, 3])\n",
            "torch.Size([3, 3])\n"
          ]
        }
      ],
      "source": [
        "model = TextCNN().to(device)\n",
        "criterion = nn.CrossEntropyLoss() #不用.to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
        "\n",
        "# Training\n",
        "for epoch in range(10):\n",
        "  for batch_x, batch_y in loader:\n",
        "    batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
        "    pred = model(batch_x)\n",
        "    loss = criterion(pred, batch_y)\n",
        "    if (epoch + 1) % 1000 == 0:\n",
        "        print('Epoch:', '%04d' % (epoch + 1), 'loss =', '{:.6f}'.format(loss))\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "colab_type": "code",
        "id": "r6fMUzoKQP6O",
        "outputId": "a87cb734-4375-4bea-a766-48d6e0b39578"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "i hate me is Good Mean!!\n"
          ]
        }
      ],
      "source": [
        "# Test\n",
        "test_text = 'i hate me'\n",
        "tests = [[word2idx[n] for n in test_text.split()]]\n",
        "test_batch = torch.LongTensor(tests).to(device)\n",
        "# Predict\n",
        "model = model.eval() #开eval模式，就是把参数更新模式关掉，不用算偏导了\n",
        "predict = model(test_batch).data.max(1, keepdim=True)[1]\n",
        "if predict[0][0] == 0:\n",
        "    print(test_text,\"is Bad Mean...\")\n",
        "else:\n",
        "    print(test_text,\"is Good Mean!!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "LNREgu9WARks"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "“TextCNN-Torch.ipynb”的副本",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.9.11 ('week6')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.11"
    },
    "vscode": {
      "interpreter": {
        "hash": "dc22443302a7e1520fd496d19808d411f95cd97f052bed8809baa60e4c089c3b"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
